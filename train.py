# -*- coding: utf-8 -*-
"""train.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/156XuvYYVleD6i9n-motQ9gN4bx8mT7HA
"""

""" from google.colab import files
uploaded = files.upload() """

"""# **Fase 3: Ingenier√≠a de Caracter√≠sticas y Preprocesamiento**"""

import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# 1. Cargar tus datos (aseg√∫rate de que ckd_cleaned.csv est√© en la carpeta)
print("‚è≥ Cargando datos para configurar el transformador...")
df = pd.read_csv('ckd_cleaned.csv')

# Separamos las caracter√≠sticas (X) de la etiqueta (y) para configurar el pipeline
X = df.drop('class', axis=1)

# 2. Identificar tipos de columnas autom√°ticamente
numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

print(f"   -> Columnas Num√©ricas detectadas: {len(numeric_cols)}")
print(f"   -> Columnas Categ√≥ricas detectadas: {len(categorical_cols)}")

# 3. Construcci√≥n del ColumnTransformer (Requisito 3.1)

# A. Pipeline para Num√©ricas:
#    - Imputaci√≥n: Usamos la mediana para rellenar huecos.
#    - Escalado: StandardScaler para poner todo en la misma escala.
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# B. Pipeline para Categ√≥ricas:
#    - Imputaci√≥n: Usamos la moda ('most_frequent') si falta alg√∫n dato.
#    - OneHotEncoding: Convierte texto a n√∫meros binarios.
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# C. Unir todo en el ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

print("\n‚úÖ Requisito 3.1 Completado: 'preprocessor' (ColumnTransformer) creado exitosamente.")
print(preprocessor)

# --- REQUISITO 3.2: CREACI√ìN DE NUEVAS CARACTER√çSTICAS ---

# 1. Ingenier√≠a de la Caracter√≠stica 1: Ratio Hemoglobina / PCV
# Justificaci√≥n: En el EDA vimos una correlaci√≥n de 0.87 entre 'hemo' y 'pcv'.
# Crear un ratio captura la relaci√≥n entre densidad y volumen, ayudando a detectar anomal√≠as espec√≠ficas.
# Sumamos 1e-5 para evitar errores de divisi√≥n por cero.
df['hemo_pcv_ratio'] = df['hemo'] / (df['pcv'] + 1e-5)

# 2. Ingenier√≠a de la Caracter√≠stica 2: Score de Riesgo (Comorbilidad)
# Justificaci√≥n: El EDA mostr√≥ que el 100% de hipertensos y la mayor√≠a de diab√©ticos tienen CKD.
# Un puntaje que sume estas dos condiciones aislar√° a los pacientes de "alto riesgo".

# Primero, aseguramos que las columnas sean num√©ricas (1 y 0) para poder sumarlas
mapping = {'yes': 1, 'no': 0, 'si': 1, 'ckd': 1, 'notckd': 0}

# Aplicamos el mapeo solo si las columnas siguen siendo texto
if df['htn'].dtype == 'object':
    df['htn'] = df['htn'].map(mapping)
if df['dm'].dtype == 'object':
    df['dm'] = df['dm'].map(mapping)

# Creamos la suma
df['risk_score'] = df['htn'] + df['dm']

# --- VERIFICACI√ìN ---
print("‚úÖ Ingenier√≠a de Caracter√≠sticas completada.")
print("Vista previa de las nuevas columnas:")
print(df[['hemo', 'pcv', 'hemo_pcv_ratio', 'htn', 'dm', 'risk_score']].head())

"""# **Fase 4: Selecci√≥n de Caracter√≠sticas y Modelado Base**"""

# --- FASE 4.1: MODELO BASE (BASELINE) ---
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score

# 1. PREPARACI√ìN FINAL DE DATOS
# Aseguramos que X incluya las nuevas columnas de la Fase 3
X = df.drop('class', axis=1)
y = df['class']

# 2. DIVISI√ìN ESTRATIFICADA (Requisito 4.1)
# stratify=y asegura que si hay 60% enfermos en el total,
# haya 60% enfermos en el entrenamiento y 60% en la prueba.
print(" Dividiendo datos (Train/Test)...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# 3. CREACI√ìN DEL PIPELINE COMPLETO (Requisito 4.1)
# Unimos el preprocesador (que ya creamos) con el clasificador Random Forest
baseline_pipeline = Pipeline([
    ('preprocessor', preprocessor), # Tu limpieza autom√°tica
    ('clf', RandomForestClassifier(random_state=42)) # El modelo
])

# 4. ENTRENAMIENTO DEL MODELO BASE (Requisito 4.1)
print(" Entrenando Modelo Base con TODAS las caracter√≠sticas...")
baseline_pipeline.fit(X_train, y_train)

# 5. EVALUACI√ìN
print(" Entrenamiento finalizado.")
y_pred_base = baseline_pipeline.predict(X_test)
acc_base = accuracy_score(y_test, y_pred_base)

print(f"\n EXACTITUD DEL MODELO BASE: {acc_base:.4f}")
print("-" * 60)
print("Reporte de Clasificaci√≥n:")
print(classification_report(y_test, y_pred_base))

# --- FASE 4.2: COMPARATIVA DE SELECCI√ìN DE CARACTER√çSTICAS ---
from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel
from sklearn.linear_model import LogisticRegression

print(" Iniciando Selecci√≥n de Caracter√≠sticas...")

# Paso A: Necesitamos transformar X_train a n√∫meros antes de seleccionar
# El algoritmo matem√°tico no entiende texto como 'yes' o 'abnormal'
X_train_numerico = preprocessor.fit_transform(X_train)

# Truco para obtener los nombres reales de las columnas despu√©s de la transformaci√≥n
try:
    nombres_columnas = preprocessor.get_feature_names_out()
except:
    # Si falla (versiones viejas de sklearn), usamos nombres gen√©ricos
    nombres_columnas = [f"col_{i}" for i in range(X_train_numerico.shape[1])]

# --- M√âTODO 1: FILTRO (SelectKBest) [Requisito 65] ---
# Elige las 10 caracter√≠sticas con mayor "informaci√≥n mutua" (relaci√≥n estad√≠stica)
print("\n1Ô∏è‚É£  Ejecutando M√©todo de Filtro (SelectKBest)...")
selector_filtro = SelectKBest(score_func=mutual_info_classif, k=10)
selector_filtro.fit(X_train_numerico, y_train)

# Obtenemos los nombres de las que ganaron
cols_filtro = nombres_columnas[selector_filtro.get_support()]
print(f"   -> Seleccionadas ({len(cols_filtro)}):")
print(list(cols_filtro))

# --- M√âTODO 2: WRAPPER (SelectFromModel) [Requisito 66] ---
# Usa una Regresi√≥n Log√≠stica con penalidad L1 (Lasso) que "castiga" a las variables in√∫tiles volvi√©ndolas cero.
print("\n2Ô∏è‚É£  Ejecutando M√©todo Wrapper (Lasso)...")
# Usamos solver='liblinear' porque es bueno para datasets peque√±os
selector_wrapper = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear', random_state=42))
selector_wrapper.fit(X_train_numerico, y_train)

# Obtenemos los nombres de las que ganaron
cols_wrapper = nombres_columnas[selector_wrapper.get_support()]
print(f"   -> Seleccionadas ({len(cols_wrapper)}):")
print(list(cols_wrapper))

# --- FASE 4.3: MODELO OPTIMIZADO ---
# Entrenar un Random Forest usando SOLO las caracter√≠sticas seleccionadas por el Wrapper

print(" Entrenando Modelo Optimizado (Solo con las 14 variables seleccionadas)...")

# 1. Definimos el Pipeline Optimizado
# Incluimos el selector 'Wrapper' dentro del flujo.
# Esto filtrar√° autom√°ticamente las columnas antes de llegar al Random Forest.
pipeline_opt = Pipeline([
    ('preprocessor', preprocessor),
    ('selector', selector_wrapper), # Este paso elimina las variables "in√∫tiles"
    ('clf', RandomForestClassifier(random_state=42))
])

# 2. Entrenamiento
pipeline_opt.fit(X_train, y_train)

# 3. Evaluaci√≥n
y_pred_opt = pipeline_opt.predict(X_test)
acc_opt = accuracy_score(y_test, y_pred_opt)

print(f"‚úÖ Exactitud Modelo Optimizado: {acc_opt:.4f}")
print("-" * 60)
print("¬øPerdimos calidad al quitar variables?")
print(f"Base (25 vars): {acc_base:.4f} vs Optimizado (14 vars): {acc_opt:.4f}")

if acc_opt >= acc_base:
    print(" CONCLUSI√ìN: El modelo es m√°s eficiente. Mismo rendimiento con menos datos.")
else:
    print("üëâ CONCLUSI√ìN: Ligera p√©rdida, pero el modelo es m√°s simple (menos riesgo de overfitting).")

"""# **Fase 5: Optimizaci√≥n de Hiperpar√°metros y MLOps**"""

# --- FASE 5.1: B√öSQUEDA DE HIPERPAR√ÅMETROS (TUNING) ---
from sklearn.model_selection import GridSearchCV

print(" Iniciando optimizaci√≥n de hiperpar√°metros (GridSearchCV)...")

# 1. Definimos la "Rejilla" de opciones a probar (Hyperparameter Grid)
# El examen sugiere probar n_estimators y max_depth
param_grid = {
    'clf__n_estimators': [50, 100, 200],   # N√∫mero de √°rboles en el bosque
    'clf__max_depth': [None, 10, 20],      # Profundidad m√°xima de cada √°rbol
    'clf__min_samples_split': [2, 5]       # M√≠nimo de datos para dividir un nodo
}

# 2. Configuramos la b√∫squeda
# Usamos el 'pipeline_opt' que creamos en el paso anterior
grid_search = GridSearchCV(
    pipeline_opt,       # Tu modelo optimizado
    param_grid,         # Las opciones a probar
    cv=3,               # Validaci√≥n cruzada (divide en 3 partes)
    scoring='accuracy', # Buscamos maximizar la exactitud
    n_jobs=-1,          # Usa todos los n√∫cleos del procesador
    verbose=1
)

# 3. Entrenamos (Esto probar√° todas las combinaciones posibles)
grid_search.fit(X_train, y_train)

# 4. Resultados
best_model = grid_search.best_estimator_
y_pred_tuned = best_model.predict(X_test)
acc_tuned = accuracy_score(y_test, y_pred_tuned)

print("\n RESULTADOS DEL TUNING:")
print(f"   -> Mejor Exactitud (Tuned): {acc_tuned:.4f}")
print(f"   -> Mejores Par√°metros Encontrados: {grid_search.best_params_}")

# Comparaci√≥n final
if acc_tuned > acc_opt:
    print("‚úÖ ¬°Mejora conseguida con el Tuning!")
elif acc_tuned == acc_opt:
    print("üîπ El rendimiento se mantuvo igual (el modelo base ya era muy bueno).")

# !pip install mlflow

# --- REPARACI√ìN Y FASE 5.2: REGISTRO EN MLFLOW ---
# !pip install mlflow
import mlflow
import mlflow.sklearn
import joblib
from sklearn.metrics import f1_score, accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

print("üîß Reconstruyendo variables para el registro...")

# 1. Aseguramos que existan los MODELOS (Para evitar el NameError)
# Re-entrenamos r√°pido para tener las variables listas en memoria

# A) Baseline (Run 1)
pipeline_base = Pipeline([
    ('preprocessor', preprocessor),
    ('clf', RandomForestClassifier(random_state=42))
])
pipeline_base.fit(X_train, y_train)
acc_base = accuracy_score(y_test, pipeline_base.predict(X_test))

# B) Optimized (Run 2) - Usando el selector que ya ten√≠as
pipeline_opt = Pipeline([
    ('preprocessor', preprocessor),
    ('selector', selector_wrapper), # Tu selector Lasso
    ('clf', RandomForestClassifier(random_state=42))
])
pipeline_opt.fit(X_train, y_train)
acc_opt = accuracy_score(y_test, pipeline_opt.predict(X_test))

# C) Tuned (Run 3) - Usando los mejores par√°metros que encontraste
# (Seg√∫n tu resultado anterior: n_estimators=100, max_depth=None)
pipeline_tuned = Pipeline([
    ('preprocessor', preprocessor),
    ('selector', selector_wrapper),
    ('clf', RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42))
])
pipeline_tuned.fit(X_train, y_train)
best_model = pipeline_tuned # Este es el modelo final
acc_tuned = accuracy_score(y_test, best_model.predict(X_test))

print("‚úÖ Variables reconstruidas. Iniciando MLflow...")

# 2. AHORA S√ç: REGISTRO EN MLFLOW (Sin errores)
mlflow.set_experiment("Proyecto_CKD_Nexus")

# --- RUN 1 ---
with mlflow.start_run(run_name="Run 1: Baseline_Model"):
    y_pred = pipeline_base.predict(X_test)
    mlflow.log_metric("accuracy", acc_base)
    mlflow.log_metric("f1_score", f1_score(y_test, y_pred))
    mlflow.log_param("tipo", "Baseline")
    print(f"üìù Run 1 Registrado (Acc: {acc_base:.4f})")

# --- RUN 2 ---
with mlflow.start_run(run_name="Run 2: Optimized_Model"):
    y_pred = pipeline_opt.predict(X_test)
    mlflow.log_metric("accuracy", acc_opt)
    mlflow.log_metric("f1_score", f1_score(y_test, y_pred))
    mlflow.log_param("tipo", "Optimized")
    print(f"üìù Run 2 Registrado (Acc: {acc_opt:.4f})")

# --- RUN 3 ---
with mlflow.start_run(run_name="Run 3: Tuned_Model"):
    y_pred = best_model.predict(X_test)
    mlflow.log_metric("accuracy", acc_tuned)
    mlflow.log_metric("f1_score", f1_score(y_test, y_pred))
    mlflow.log_param("tipo", "Tuned")

    # Guardamos el modelo en MLflow
    mlflow.sklearn.log_model(best_model, "model")
    print(f"üìù Run 3 Registrado (Acc: {acc_tuned:.4f})")

# 3. GUARDAR ARCHIVO FINAL
joblib.dump(best_model, 'pipeline_final.joblib')
print("\nüíæ EXITO Archivo pipeline_final.joblib guardado.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile train.py
# import logging
# import warnings
# import pandas as pd
# import numpy as np
# import joblib
# import mlflow
# import mlflow.sklearn
# from sklearn.model_selection import train_test_split, GridSearchCV
# from sklearn.impute import SimpleImputer
# from sklearn.preprocessing import StandardScaler, OneHotEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.feature_selection import SelectFromModel
# from sklearn.linear_model import LogisticRegression
# from sklearn.metrics import accuracy_score, f1_score
# 
# # --- CONFIGURACI√ìN: SILENCIAR ADVERTENCIAS ---
# # Esto ayuda a limpiar la salida de la terminal
# warnings.filterwarnings('ignore')
# logging.getLogger("mlflow").setLevel(logging.ERROR)
# 
# # --- 1. CARGA DE DATOS ---
# def load_data(filepath='ckd_cleaned.csv'):
#     """Carga el dataset limpio."""
#     return pd.read_csv(filepath)
# 
# # --- 2. INGENIER√çA DE CARACTER√çSTICAS (Fase 3.2) ---
# def feature_engineering(df):
#     """Crea las nuevas variables ratio y risk_score."""
#     df_eng = df.copy()
# 
#     # Ratio Hemoglobina / PCV
#     df_eng['hemo_pcv_ratio'] = df_eng['hemo'] / (df_eng['pcv'] + 1e-5)
# 
#     # Score de Riesgo (Suma de Hipertensi√≥n + Diabetes)
#     mapping = {'yes': 1, 'no': 0, 'si': 1, 'ckd': 1, 'notckd': 0}
#     for col in ['htn', 'dm']:
#         if df_eng[col].dtype == 'object':
#              df_eng[col] = df_eng[col].map(mapping)
# 
#     df_eng['risk_score'] = df_eng['htn'] + df_eng['dm']
#     return df_eng
# 
# # --- 3. PIPELINE DE PREPROCESAMIENTO (Fase 3.1) ---
# def get_preprocessor(X):
#     numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
#     categorical_cols = X.select_dtypes(include=['object']).columns
# 
#     num_transformer = Pipeline(steps=[
#         ('imputer', SimpleImputer(strategy='median')),
#         ('scaler', StandardScaler())
#     ])
#     cat_transformer = Pipeline(steps=[
#         ('imputer', SimpleImputer(strategy='most_frequent')),
#         ('onehot', OneHotEncoder(handle_unknown='ignore'))
#     ])
# 
#     preprocessor = ColumnTransformer(transformers=[
#         ('num', num_transformer, numeric_cols),
#         ('cat', cat_transformer, categorical_cols)
#     ])
#     return preprocessor
# 
# # --- 4. EJECUCI√ìN PRINCIPAL (Fases 4 y 5) ---
# def main():
#     mlflow.set_experiment("Proyecto_CKD_Nexus")
# 
#     print(" Ejecutando pipeline completo de entrenamiento...")
#     df = load_data()
#     df = feature_engineering(df)
#     X = df.drop('class', axis=1)
#     y = df['class']
# 
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
#     preprocessor = get_preprocessor(X_train)
# 
#     # --- Run 1: Baseline ---
#     with mlflow.start_run(run_name="Run 1: Baseline"):
#         pipe = Pipeline([('prep', preprocessor), ('clf', RandomForestClassifier(random_state=42))])
#         pipe.fit(X_train, y_train)
#         acc = accuracy_score(y_test, pipe.predict(X_test))
#         mlflow.log_metric("accuracy", acc)
#         print(f"‚úÖ Run 1 (Baseline): {acc:.4f}")
# 
#     # Selecci√≥n de Caracter√≠sticas (Wrapper/Lasso)
#     selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear', random_state=42))
# 
#     # --- Run 2: Optimized ---
#     with mlflow.start_run(run_name="Run 2: Optimized"):
#         pipe_opt = Pipeline([('prep', preprocessor), ('sel', selector), ('clf', RandomForestClassifier(random_state=42))])
#         pipe_opt.fit(X_train, y_train)
#         acc = accuracy_score(y_test, pipe_opt.predict(X_test))
#         mlflow.log_metric("accuracy", acc)
#         print(f"‚úÖ Run 2 (Optimized): {acc:.4f}")
#         best_pipeline = pipe_opt
# 
#     # --- Run 3: Tuned ---
#     with mlflow.start_run(run_name="Run 3: Tuned"):
#         param_grid = {'clf__n_estimators': [100, 200], 'clf__max_depth': [None, 10]}
#         grid = GridSearchCV(best_pipeline, param_grid, cv=3, scoring='accuracy')
#         grid.fit(X_train, y_train)
# 
#         best_model = grid.best_estimator_
#         acc = accuracy_score(y_test, best_model.predict(X_test))
#         mlflow.log_metric("accuracy", acc)
#         mlflow.sklearn.log_model(best_model, "model")
#         print(f"‚úÖ Run 3 (Tuned): {acc:.4f}")
# 
#         # Guardar el artefacto final
#         joblib.dump(best_model, 'pipeline_final.joblib')
#         print(" Modelo final guardado: pipeline_final.joblib")
# 
# if __name__ == "__main__":
#     main()

# !python train.py